#summary user guide.
#labels Featured,Phase-Support

= User Guide =

TTC TermSuite is the name of the tool provided [http://ttc-project.googlecode.com/files/ttc-term-suite-1.1.jar here] as an executable Java archive. This archive also owns hundreds of 
UIMA analysis engines runnable by the help of an appropriate tool. 
This user guide page explains how to install and use it.

== Installation == 

=== Prerequisites ===

Before installing Term Suite on your computer, 
you have to install a Java Runtime Environment 
and the TreeTagger part-of-speech tagger.

Notice that you don't have to install neither the Java library Apache UIMA, nor the Java library tt4j as the TTC TermSuite Java archive already contains them.

==== Java Runtime Environment ====

Several JREs exist: for instance that of [http://www.java.com/fr/download/ Sun's] or [http://openjdk.java.net/install/ OpenJDK].

Just check that the Java program is installed on your computer by running this following command line:

{{{
  java -version
}}}

==== TreeTagger ====

Notice that the TreeTagger executable called _tree-tagger_ on Unix-based systems or _tree-tagger.exe_ on Windows ones is expected in the _bin/_ sub-directory of the TreeTagger home directory. 

Moreover, the language model parameter files for TreeTagger are expected to stand in the _models/_ sub-directory of the TreeTagger home one.

If parameter files lie in the _lib/_ subdirectory, please create a symbolic link to this directory as follows:

{{{
  cd /path/to/tree-tagger-home-directory
  ln -s lib models
}}}

I order to check if TreeTagger is correctly installed, 
please launch this command line:

{{{
  cd tree-tagger-home-directory
  ./bin/tree-tagger ./models/english.par
}}}

Exit the program by the keyboard short-cut Ctrl+D.

=== Install ===

As Term Suite is provided as an executable Java archive, 
you merely have to download it and put it 
wherever you want on your computer. 

There is no any packages of Term Suite for any distributions.

Otherwise, you can regenerate the Java archive from 
Term Suite source code. You then need both Subversion and Maven2 
respectively for getting the source code and for packaging it.

==== Download the binary ====

Just launch this command line or follow its target link:

{{{
 wget http://ttc-project.googlecode.com/files/ttc-term-suite-1.1.jar
}}}

==== Compilation from Sources ====

In order to regenerate the Term Suite package, 
you first have to download the source code from 
the Subversion repository hosted by Google Code. 
Then using Maven, install every dependencies (modules) 
in your local Maven repository.
Finally, generate the Term Suite Java archive. 
That's the way, the Term Suite is build.

In few words, just launch these command lines:

{{{
 svn checkout http://ttc-project.googlecode.com/svn/trunk ttc-term-suite
 cd ttc-term-suite/modules
 for module in * ; do cd $module ; mvn install ; cd .. ; done
 cd ..
 mvn -f pom-term-suite.xml package
}}}

== Execution == 

You merely have to launch the following command line:

{{{
  java -Xms1g -Xmx4g -jar ttc-term-suite-1.1.jar
}}}

You are strongly suggested to set the JVM options -Xms1g 
that allocate 1Go of RAM memory for this program 
as terminology compilation and terminology alignment 
each requires a certain amount of memory even for corpora 
which sizes are around 300.000 tokens.

== Description ==

Having launched the previous command line, you face the Term Suite graphical user interface:

http://ttc-project.googlecode.com/files/spotter.png

It is basically made of a tool bar and 3 tabbed panels 
respectively called: Spotter, Indexer and Aligner.

=== Tool Bar ===

The tool bar contains 5 buttons and a progress bar which acts as follows when activated:

 * the button About pops up a dialog with a tiny description of Term Suite.
 * the button Run executes the UIMA component corresponding to the selected tab
 * the button Stop is enabled when a UIMA component is under processing and interrupts the latter.
 * the progress bar displays the progress of the execution task.
 * the button Save makes possible to store the parameter values of every tabbed panels.
 * the button Quit pops up a confirm dialog for exiting Term Suite.

=== Spotter ===

The Spotter tabbed panel has 2 embedded tabbed panels itself. 
The first one called Edit makes possible to configure the UIMA component 
that can be executed. The View panel displays its processing results. 

In fact, UIMA components that can be executed by the Spotter performs:
 * word tokenization,
 * part-of-speech tagging and lemmatization thanks to TreeTagger,
 * tag normalization from the different language-dependent tagsets of TreeTagger according to the Multext standard,
 * stemming using Porter's algorithm,
 * single-word and multi-word term occurrences detection,
 * stop-word filtering,
 * contextual window computing.

It merely accepts text files as inputs and generates a XMI file in the output directory per text file in the input directory.

The Spotter requires the following parameters to be set:
  * the parameter _Language_ should be one of the languages given in the selection list,
  * the parameter _Input Directory_ should refer to the directory where the text files are,
  * the parameter _Output Directory_ should refer to the folder where  the XMI  files will be written,
  * the parameter _TreeTagger Home Directory_ should refer to the directory where TreeTagger has been installed on your computer.

==== Note ====

Make sure that the TreeTagger parameter file that corresponds to the selected language of the Spotter exists in models/_ subdirectory of the TreeTagger home one. Otherwise, Term Suite will exit abnormally. 

Moreover, make sure that these parameter file have the following encoding although TreeTagger lemmatization will return unexpected values. The table above explains for each language which parameter file is expected in the TreeTagger _models/ subdirectory and its encoding.

|| Language || Parameter File || Encoding ||
|| English || english.par || iso8859-1 ||
|| French || french.par || iso8859-1 ||
|| German || german.par || iso8859-1 ||
|| Spanish || spanish.par || iso8859-1 ||
|| Russian || russian.par || utf-8 ||
|| Danish || danish.par || iso8859-1 ||
|| Latvian ||  ||  ||
|| Chinese || zh.par || utf-8 ||

The Latvian language isn't yet supported by this version of Term Suite.

=== Indexer ===

The Acabit GUI provides a tool bar to launch and monitor the Collection Processing Engine, a tab for setting the CPE parameters, a tab for viewing the extracted terminology and a tab for viewing the processing results. 

Tha Acabit CPE performs:
  * single-word term detection,
  * rule-based multi-word term detection,
  * term bank filtering.
It requires XMI files previously generated by the TreeTagger CPE as inputs.
It generates a XMI file in the output directory per XMI file in the input directory and another XMI file that stands for the terminology bank.

The Acabit CPE requires the following parameters to be set:
  * Language: the 2-letter code for the language of text files in the input directory;
  * Input Directory: the folder where reading the XMI files;
  * Output Directory: the folder where writing the XMI  files;
  * Terminology File: the file that contains the term bank.

=== Aligner === 

The Ziggurat GUI provides a tool bar to launch and monitor the Collection Processing Engine, a tab for setting the CPE parameters and a tab for viewing the processing results. 

Tha Ziggurat CPE performs:
  * single-word term alignment.
It requires XMI files previously generated by the Acabit CPE as inputs both for the source language and the target one.
It generates a text file containing alignment results.

The Ziggurat CPE requires the following parameters to be set:
  * Source Language: the 2-letter code for the language of text files in the source directory;
  * Source Input Directory: the source folder where reading the XMI files;
  * Source Terminology File: the file that contains the source term bank;
  * Target Language: the 2-letter code for the language of text files in the target directory;
  * Target Input Directory: the target folder where reading the XMI files;
  * Target Terminology File: the file that contains the target term bank;
  * Alignment File: the file that contains the alignment results;
  * Scope Size: the context vector size given by the maximum number of terms before and after a given term;
  * Association Rate: the class name of the association rate, two allowed values:
    * eu.project.ttc.metrics.LogLikelihood 
    * eu.project.ttc.metrics.MutualInformation
  * Similarity Distance: the class name of the similarity distance, two values allowed;
    * eu.project.ttc.metrics.Jaccard
    * eu.project.ttc.metrics.Cosinus
  * Dictionary File: the bilingual dictionary;
  * Evaluation List File: the term to translate and their gold standard translation;