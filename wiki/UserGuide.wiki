#summary user guide.
#labels Featured,Phase-Support

= User Guide =

TTC TermSuite is the name of the tool provided [http://ttc-project.googlecode.com/files/ttc-term-suite-1.1.jar here] as an executable Java archive. This archive also owns hundreds of 
UIMA analysis engines runnable by the help of an appropriate tool. 
This user guide page explains how to install and use it.

== Installation == 

=== Prerequisites ===

Before installing Term Suite on your computer, 
you have to install a Java Runtime Environment 
and the TreeTagger part-of-speech tagger.

Notice that you don't have to install neither the Java library Apache UIMA, nor the Java library tt4j as the TTC TermSuite Java archive already contains them.

==== Java Runtime Environment ====

Several JREs exist: for instance that of [http://www.java.com/fr/download/ Sun's] or [http://openjdk.java.net/install/ OpenJDK].

Just check that the Java program is installed on your computer by running this following command line:

{{{
  java -version
}}}

==== TreeTagger ====

Notice that the TreeTagger executable called _tree-tagger_ on Unix-based systems or _tree-tagger.exe_ on Windows ones is expected in the _bin/_ sub-directory of the TreeTagger home directory. 

Moreover, the language model parameter files for TreeTagger are expected to stand in the _models/_ sub-directory of the TreeTagger home one.

If parameter files lie in the _lib/_ subdirectory, please create a symbolic link to this directory as follows:

{{{
  cd /path/to/tree-tagger-home-directory
  ln -s lib models
}}}

I order to check if TreeTagger is correctly installed, 
please launch this command line:

{{{
  cd tree-tagger-home-directory
  ./bin/tree-tagger ./models/english.par
}}}

Exit the program by the keyboard short-cut Ctrl+D.

=== Install ===

As Term Suite is provided as an executable Java archive, 
you merely have to download it and put it 
wherever you want on your computer. 

There is no any packages of Term Suite for any distributions.

Otherwise, you can regenerate the Java archive from 
Term Suite source code. You then need both Subversion and Maven2 
respectively for getting the source code and for packaging it.

==== Download the binary ====

Just launch this command line or follow its target link:

{{{
 wget http://ttc-project.googlecode.com/files/ttc-term-suite-1.1.jar
}}}

==== Compilation from Sources ====

In order to regenerate the Term Suite package, 
you first have to download the source code from 
the Subversion repository hosted by Google Code. 
Then using Maven, install every dependencies (modules) 
in your local Maven repository.
Finally, generate the Term Suite Java archive. 
That's the way, the Term Suite is build.

In few words, just launch these command lines:

{{{
 svn checkout http://ttc-project.googlecode.com/svn/trunk ttc-term-suite
 cd ttc-term-suite/modules
 for module in * ; do cd $module ; mvn install ; cd .. ; done
 cd ..
 mvn -f pom-term-suite.xml package
}}}

== Execution == 

You merely have to launch the following command line:

{{{
  java -Xms1g -Xmx4g -jar ttc-term-suite-1.1.jar
}}}

You are strongly suggested to set the JVM options -Xms1g 
that allocate 1Go of RAM memory for this program 
as terminology compilation and terminology alignment 
each requires a certain amount of memory even for corpora 
which sizes are around 300.000 tokens.

== Description ==

Having launched the previous command line, you face the Term Suite graphical user interface:

http://ttc-project.googlecode.com/files/spotter.png

It is basically made of a tool bar and 3 tabbed panels 
respectively called: Spotter, Indexer and Aligner.

=== Tool Bar ===

The tool bar contains 5 buttons and a progress bar which acts as follows when activated:

 * the button About pops up a dialog with a tiny description of Term Suite.
 * the button Run executes the UIMA component corresponding to the selected tab
 * the button Stop is enabled when a UIMA component is under processing and interrupts the latter.
 * the progress bar displays the progress of the execution task.
 * the button Save makes possible to store the parameter values of every tabbed panels.
 * the button Quit pops up a confirm dialog for exiting Term Suite.

=== Spotter ===

The Spotter tabbed panel has 2 embedded tabbed panels itself. 
The first one called Edit makes possible to configure the UIMA component 
that can be executed. The View panel displays its processing results. 

In fact, UIMA components that can be executed by the Spotter performs:
 * word tokenization,
 * part-of-speech tagging and lemmatization thanks to TreeTagger,
 * tag normalization from the different language-dependent tagsets of TreeTagger according to the Multext standard,
 * stemming using Porter's algorithm,
 * single-word and multi-word term occurrences detection,
 * stop-word filtering,
 * contextual window computing.

It merely accepts text files as inputs and generates a XMI file in the output directory per text file in the input directory.

The Spotter requires the following parameters to be set:
  * the parameter _Language_ should be one of the languages given in the selection list,
  * the parameter _Input Directory_ should refer to the directory where the text files are,
  * the parameter _Output Directory_ should refer to the folder where  the XMI  files will be written,
  * the parameter _TreeTagger Home Directory_ should refer to the directory where TreeTagger has been installed on your computer.

==== Note ====

Make sure that the TreeTagger parameter file that corresponds to the selected language of the Spotter exists in _models/_ subdirectory of the TreeTagger home one. Otherwise, Term Suite will exit abnormally. 

Moreover, make sure that these parameter file have the following encoding although TreeTagger lemmatization will return unexpected values. The table above explains for each language which parameter file is expected in the TreeTagger _models/_ subdirectory and its encoding.

|| Language || Parameter File || Encoding ||
|| English || english.par || iso8859-1 ||
|| French || french.par || iso8859-1 ||
|| German || german.par || iso8859-1 ||
|| Spanish || spanish.par || iso8859-1 ||
|| Russian || russian.par || utf-8 ||
|| Danish || danish.par || iso8859-1 ||
|| Latvian ||  ||  ||
|| Chinese || zh.par || utf-8 ||

The Latvian language isn't yet supported by this version of Term Suite.

=== Indexer ===

The Indexer tabbed panel provides 2 embedded tabbed panels too; 
one called Edit for settings parameter values of the corresponding 
UIMA components, the other for viewing generated terminology. 

http://ttc-project.googlecode.com/files/indexer.png

It makes possible to perform:
  * single-word and multi-word term indexation,
  * term context building and normalization according to an association rate,
  * relative frequency and domain specificity computing,
  * classical and neoclassical compound detection over single-word terms,
  * graphical, morphological and syntactical term variant conflating,
  * hapax term filtering.

It requires as inputs the XMI files previously generated by the Spotter for the corresponding language. It then generates 2 files in the given output directory:
 * a XMI file _language_-terminology.xmi that corresponds to the compiled monolingual terminology,
 * a TBX file _language_-terminology.tbx that also corresponds to this terminology.

The Indexer requires the following parameters to be set:
  * the parameter _Language_ should define defines the language of the XMI files in the input directory,
  * the parameter _Input Directory_ should refer the directory where the XMI files are,
  * the parameter _Output Directory_ should refer to the directory where the XMI and TBX files will be written,
  * the parameter _Hapax Filtering Threshold_ should define a natural integer which value specifies the maximum term occurrences of hapax,
  * the parameter _Association Rate Class Name_ defines the implementation that realizes the association rate: its value could either be either LogLikelihood or MutualInformation,
  * the parameter _Enable Term Conflating_ makes possible to perform term conflation or not,
  * the parameter _Edit Distance Class Name_ defines the implementation that realzes the edit distance based similarity measure: it could either be Levenshtein or LongestCommonSubsequence,
  * the parameter _Edit Distance Threshold_ specifies the minimum value for conflating terms together using the edit-distance approach: it should be a value between 0 and 1,
  * the parameter _Edit Distance Ngrams_ defines the numbers of charcters taken in account while measuring the edit distance between two terms: it should be an integer between 1 and 3.

=== Aligner === 

The Ziggurat GUI provides a tool bar to launch and monitor the Collection Processing Engine, a tab for setting the CPE parameters and a tab for viewing the processing results. 

http://ttc-project.googlecode.com/files/aligner.png

Tha Ziggurat CPE performs:
  * single-word term alignment.
It requires XMI files previously generated by the Acabit CPE as inputs both for the source language and the target one.
It generates a text file containing alignment results.

The Ziggurat CPE requires the following parameters to be set:
  * Source Language: the 2-letter code for the language of text files in the source directory;
  * Source Input Directory: the source folder where reading the XMI files;
  * Source Terminology File: the file that contains the source term bank;
  * Target Language: the 2-letter code for the language of text files in the target directory;
  * Target Input Directory: the target folder where reading the XMI files;
  * Target Terminology File: the file that contains the target term bank;
  * Alignment File: the file that contains the alignment results;
  * Scope Size: the context vector size given by the maximum number of terms before and after a given term;
  * Association Rate: the class name of the association rate, two allowed values:
    * eu.project.ttc.metrics.LogLikelihood 
    * eu.project.ttc.metrics.MutualInformation
  * Similarity Distance: the class name of the similarity distance, two values allowed;
    * eu.project.ttc.metrics.Jaccard
    * eu.project.ttc.metrics.Cosinus
  * Dictionary File: the bilingual dictionary;
  * Evaluation List File: the term to translate and their gold standard translation;