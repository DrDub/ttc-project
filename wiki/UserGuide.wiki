#summary user guide.
#labels Featured,Phase-Support

= User Guide =

TTC TermSuite is the name of the tool provided [http://ttc-project.googlecode.com/files/ttc-term-suite-1.1.jar here] as an executable Java archive. This archive also owns hundreds of 
UIMA analysis engines runnable by the help of an appropriate tool. 
This user guide page explains how to install and use it.

== Installation == 

=== Prerequisites ===

Before installing Term Suite on your computer, 
you have to install a Java Runtime Environment 
and the TreeTagger part-of-speech tagger.

Notice that you don't have to install neither the Java library Apache UIMA, nor the Java library tt4j as the TTC TermSuite Java archive already contains them.

==== Java Runtime Environment ====

Several JREs exist: for instance that of [http://www.java.com/fr/download/ Sun's] or [http://openjdk.java.net/install/ OpenJDK].

Just check that the Java program is installed on your computer by running this following command line:

{{{
  java -version
}}}

==== TreeTagger ====

Notice that the TreeTagger executable called _tree-tagger_ on Unix-based systems or _tree-tagger.exe_ on Windows ones is expected in the _bin/_ sub-directory of the TreeTagger home directory. 

Moreover, the language model parameter files for TreeTagger are expected to stand in the _models/_ sub-directory of the TreeTagger home one.

If parameter files lie in the _lib/_ subdirectory, please create a symbolic link to this directory as follows:

{{{
  cd /path/to/tree-tagger-home-directory
  ln -s lib models
}}}

I order to check if TreeTagger is correctly installed, 
please launch this command line:

{{{
  /path/to//tree-tagger-home-directory/bin/tree-tagger /path/to//tree-tagger-home-directory/models/english.par
}}}

Exit the program by the keyboard short-cut Ctrl+D.

=== Install ===

As Term Suite is provided as an executable Java archive, 
you merely have to download it and put it 
wherever you want on your computer. 

There is no any packages of Term Suite for any distributions.

Otherwise, you can regenerate the Java archive from 
Term Suite source code. You then need both Subversion and Maven2 
respectively for getting the source code and for packaging it.

==== Download the binary ====

Just launch this command line or follow its target link:

{{{
 wget http://ttc-project.googlecode.com/files/ttc-term-suite-1.1.jar
}}}

==== Compilation from Sources ====

In order to regenerate the Term Suite package, 
you first have to download the source code from 
the Subversion repository hosted by Google Code. 
Then using Maven, install every dependencies (modules) 
in your local Maven repository.
Finally, generate the Term Suite Java archive. 
That's the way, the Term Suite is build.

In few words, just launch these command lines:

{{{
 svn checkout http://ttc-project.googlecode.com/svn/trunk ttc-term-suite
 cd ttc-term-suite/modules
 for module in * ; do cd $module ; mvn install ; cd .. ; done
 cd ..
 mvn -f pom-term-suite.xml package
}}}

== Usage == 

You merely have to launch the following command line:

  java -jar ttc-term-suite-_version_.jar

Or you just have to open it in a Java 6 Runtime Environment. 

It then displays a tiny Graphical User Interface with the 6 following buttons:
  * About: pops up a small note about this tool;
  * Help: opens this help pages if your JRE enables desktop integration;
  * TreeTagger: launches the monolingual tagger and lemmatizer tool;
  * Acabit: launches the monolingual terminology extraction tool;
  * Ziggurat: launches the bilingual terminology alignment tool;
  * Quit: exits this tool.

=== TreeTagger ===

The TreeTagger GUI provides a tool bar to launch and monitor the Collection Processing Engine, a tab for setting the CPE parameters and a tab for viewing the processing results. 

This TreeTagger CPE performs:
  * word segmentation,
  * part-of-speech tagging
  * grammatical category normalization
  * lemmatization.
It requires text files as inputs. It generates a XMI file in the output directory per text file in the input directory.

The TreeTagger CPE requires the following parameters to be set:
  * Language: the 2-letter code for the language of text files in the input directory;
  * Input Directory: the folder where reading the text files;
  * Output Directory: the folder where writing the XMI  files;
  * TreeTagger Home Directory: the folder where TreeTagger has been installed.

=== Acabit ===

The Acabit GUI provides a tool bar to launch and monitor the Collection Processing Engine, a tab for setting the CPE parameters, a tab for viewing the extracted terminology and a tab for viewing the processing results. 

Tha Acabit CPE performs:
  * single-word term detection,
  * rule-based multi-word term detection,
  * term bank filtering.
It requires XMI files previously generated by the TreeTagger CPE as inputs.
It generates a XMI file in the output directory per XMI file in the input directory and another XMI file that stands for the terminology bank.

The Acabit CPE requires the following parameters to be set:
  * Language: the 2-letter code for the language of text files in the input directory;
  * Input Directory: the folder where reading the XMI files;
  * Output Directory: the folder where writing the XMI  files;
  * Terminology File: the file that contains the term bank.

=== Ziggurat === 

The Ziggurat GUI provides a tool bar to launch and monitor the Collection Processing Engine, a tab for setting the CPE parameters and a tab for viewing the processing results. 

Tha Ziggurat CPE performs:
  * single-word term alignment.
It requires XMI files previously generated by the Acabit CPE as inputs both for the source language and the target one.
It generates a text file containing alignment results.

The Ziggurat CPE requires the following parameters to be set:
  * Source Language: the 2-letter code for the language of text files in the source directory;
  * Source Input Directory: the source folder where reading the XMI files;
  * Source Terminology File: the file that contains the source term bank;
  * Target Language: the 2-letter code for the language of text files in the target directory;
  * Target Input Directory: the target folder where reading the XMI files;
  * Target Terminology File: the file that contains the target term bank;
  * Alignment File: the file that contains the alignment results;
  * Scope Size: the context vector size given by the maximum number of terms before and after a given term;
  * Association Rate: the class name of the association rate, two allowed values:
    * eu.project.ttc.metrics.LogLikelihood 
    * eu.project.ttc.metrics.MutualInformation
  * Similarity Distance: the class name of the similarity distance, two values allowed;
    * eu.project.ttc.metrics.Jaccard
    * eu.project.ttc.metrics.Cosinus
  * Dictionary File: the bilingual dictionary;
  * Evaluation List File: the term to translate and their gold standard translation;